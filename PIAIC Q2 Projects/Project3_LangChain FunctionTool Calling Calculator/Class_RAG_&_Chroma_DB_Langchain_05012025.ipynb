{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Working on Project2 ***\n",
        "\n",
        "Rag LangChain 03 Components (1- Retrieval System 2- Augmentation 3- Generation)\n",
        "\n",
        "Document = Image, PDF, Audio, Video, Text. etcs\n",
        "\n",
        "\n",
        "Process = **Load** + **Split** (Paragraph/Chapter/Heading) + **Embed**+ **Store**)\n",
        "\n",
        "**1- Load**\n",
        "\n",
        "**2- Splict** = Split data into paragraph or chapter or Heading etc.\n",
        "\n",
        "**3- Embeded** = in Numbers (all data conveted into numbers) number converting technique is called Embeding. Converting into numbers is called Vector. Vector database is in Numbers then we return to convert numbers into Text. \"Pinecone\"\n",
        "\n",
        "% Augmented = data retreival from numbers to text format%\n",
        "\n",
        "**{Template = Prompt (Question + Retrieval Augmented data) --> LLM --> Answer}**\n",
        "\n",
        "Tokennaization technique is very important\n",
        "\n",
        "Vectorization = Word Frequency\n",
        "\n",
        "**Task Type        =      Description **\n",
        "\n",
        "Retrieval Query  = Specify the given text is a query in a search/Retreval settings\n",
        "\n",
        "Retrieval Document = Specify the given text is a document in a search /retrieval setting. using this task type rquires\n",
        "**Symentic_Similarity **\n",
        "\n",
        "Classification\n",
        "Clustering\n",
        "\n"
      ],
      "metadata": {
        "id": "OflVUeRc0ur4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to install python\n",
        "\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9 -y"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-ZROu2Vcz49l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "tSJkzZGx8an7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "88HqxEx98gP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(genai.list_models())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "t8bVB8-f8_En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "# embedding model is best in question answers\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=\"What is the meaning of life?\",\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of single string\",\n",
        ")\n",
        "\n",
        "# # 1 input > 1 vector output\n",
        "# print(str(result[\"embedding\"])[:50], \"... TRIMMED]\")\n",
        "\n",
        "result['embedding']"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bzes00VZ_InU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(result['embedding'])"
      ],
      "metadata": {
        "id": "Nmrtsn11_l2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=[\n",
        "        \"What is the meaning of life?\",\n",
        "        \"How much wood would a woodchuck chuck?\",\n",
        "        \"How does the brain work?\",\n",
        "    ],\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of list of strings\",\n",
        ")\n",
        "\n",
        "# A list of inputs > A list of vectors output\n",
        "for v in result[\"embedding\"]:\n",
        "    print(str(v)[:50], \"... TRIMMED ...\")"
      ],
      "metadata": {
        "id": "akjAsxhp_3Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (len(result))"
      ],
      "metadata": {
        "id": "IAh44jKYADID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (len('embedding'))"
      ],
      "metadata": {
        "id": "O6z37SQfAVc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('embedding')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9lrSAIsGAK7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Vector Stores & Retreival using Chroma DB\n",
        "\n",
        "1.   List item\n",
        "2.   List item"
      ],
      "metadata": {
        "id": "UlPRODVvAjEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-chroma # Chroma DB install pcakage"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Sns6UsyGAc9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Langchain"
      ],
      "metadata": {
        "id": "hPxlx6q6BibZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gujJXHJJBglc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "0RaBpEiwBUME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document # Only convert in Class not in Embedding\"\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
        "        metadata={\"source\": \"fish-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
        "        metadata={\"source\": \"bird-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "dXVgcJ8rBsrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain_openai   # use open ai for embedding"
      ],
      "metadata": {
        "id": "9gGVSHjQCOaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open AI Key fetch\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "unPWaTo0CkD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents,\n",
        "    embedding=OpenAIEmbeddings())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7e9MpaxIDKot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJfnXmNxFkCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrievers**#\n"
      ],
      "metadata": {
        "id": "R4W-DRqbFkbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)  # select top result\n",
        "\n",
        "retriever.batch([\"cat\", \"shark\"])"
      ],
      "metadata": {
        "id": "91pwqbJ-FmC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eRauvHKBGk3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-google-genai"
      ],
      "metadata": {
        "id": "cKPXVO-lGlCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",\n",
        "                             api_key = userdata.get('GOOGLE_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "kbIx044tGtgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nZeybomjG106"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}