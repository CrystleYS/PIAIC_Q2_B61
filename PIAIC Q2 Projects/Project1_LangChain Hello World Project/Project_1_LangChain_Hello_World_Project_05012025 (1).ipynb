{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1: LangChain Hello World Project\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AU6WVTfi2bPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To installs the necessary libraries for the LangChain project.\n",
        "# LangChain is a framework for developing applications powered by language models.\n",
        "# langchain-google-genai provides integration with Google's AI models.\n",
        "\n",
        "\n",
        "!pip install langchain langchain-google-genai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5gR1QajkhTpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To imports the langchain_google_genai library,\n",
        "# which provides tools to interact with Google's AI models\n",
        "# using the LangChain framework.  The rest of your code\n",
        "# would then use functions from this library to perform\n",
        "# tasks such as text generation, summarization, translation,\n",
        "# and other language-based operations.\n",
        "\n",
        "import langchain_google_genai as genai"
      ],
      "metadata": {
        "id": "UpItAVBb_EmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The line `from langchain_google_genai import ChatGoogleGenerativeAI` imports the `ChatGoogleGenerativeAI` class from the `langchain_google_genai` library.  This class provides a way to interact with Google's large language models (LLMs) through the LangChain framework.  Essentially, it's a specialized tool within LangChain designed for conversations (chats) with Google's AI models.  You would create an instance of this class, configure it with your Google Cloud project details and model settings, and then use it to send messages and receive responses from the LLM.\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "CYobHTO9_Kav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the Google API key from user data\n",
        "GOOGLE_API_KEY= userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "Z46hYZTu_b-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code sets up a connection to Google's Gemini language model using the LangChain framework.\n",
        "\n",
        "llm: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # Latest Version of Gemini is 1.5, it is updated as version updated\n",
        "    api_key=GOOGLE_API_KEY,     # Provide the Google API key for authentication\n",
        "    temperature=0.2,            # Set the randomness of the model's responses (0 = deterministic, 1 = very random)\n",
        ")"
      ],
      "metadata": {
        "id": "nhxFohTV_q9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"HELLO WORLD TO MUHAMMAD YOUNAS\")"
      ],
      "metadata": {
        "id": "ewZF0pdFAK6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)\n",
        ""
      ],
      "metadata": {
        "id": "6C-H18nfAcEF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}